{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'feature1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-865f5c308ea9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfeature1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeaFactory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserTagsMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'feature1'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*-coding:utf-8-*-\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from scipy import sparse\n",
    "import csv\n",
    "from datetime import *\n",
    "import json, random, os\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, SelectPercentile\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from utils import *\n",
    "from feature1 import feaFactory, userTagsMatrix\n",
    "\n",
    "\n",
    "class LgbModel:\n",
    "    def __init__(self, feaName, cateFea=[], params={}):\n",
    "        self.params = {\n",
    "        \t'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'learning_rate': 0.05,\n",
    "        \t'num_leaves': 25,\n",
    "            'max_depth': -1,\n",
    "            \n",
    "            \n",
    "            # 'min_data_in_leaf': 120,\n",
    "            # 'feature_fraction': 0.9,\n",
    "            # 'bagging_fraction': 0.9,\n",
    "        \t# 'bagging_freq': 5,\n",
    "            'verbose': 0,\n",
    "        }\n",
    "        self.params.update(**params)\n",
    "        self.feaName = feaName\n",
    "        self.cateFea = cateFea\n",
    "        print(feaName)\n",
    "\n",
    "    def train(self, X, y, num_round=8000, validX=None, validy=None, early_stopping=10, verbose=True, params={}):\n",
    "        trainData = lgb.Dataset(X, label=y, feature_name=self.feaName, categorical_feature=self.cateFea)\n",
    "        trainParam = self.params\n",
    "        trainParam.update(params)\n",
    "        if isinstance(validX, (pd.DataFrame, sparse.csr_matrix)):\n",
    "            validData = trainData.create_valid(validX, label=validy)\n",
    "            bst = lgb.train(trainParam, trainData, num_boost_round=num_round, valid_sets=validData, early_stopping_rounds=early_stopping, verbose_eval=verbose)\n",
    "        else:\n",
    "            bst = lgb.train(trainParam, trainData, num_boost_round=num_round, verbose_eval=verbose)\n",
    "        self.bst = bst\n",
    "        return bst.best_iteration\n",
    "\n",
    "    def cv(self, X, y, nfold=5, num_round=8000, early_stopping=10, verbose=True, params={}):\n",
    "        trainParam = self.params\n",
    "        trainParam.update(params)\n",
    "        trainData = lgb.Dataset(X, label=y, feature_name=self.feaName, categorical_feature=self.cateFea)\n",
    "        result = lgb.cv(trainParam, trainData, feature_name=self.feaName, categorical_feature=self.cateFea, num_boost_round=num_round, nfold=nfold, early_stopping_rounds=early_stopping, verbose_eval=verbose)\n",
    "        return result\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.bst.predict(X)\n",
    "\n",
    "    def feaScore(self, show=True):\n",
    "        scoreDf = pd.DataFrame({'fea': self.feaName, 'importance': self.bst.feature_importance()})\n",
    "        scoreDf.sort_values(['importance'], ascending=False, inplace=True)\n",
    "        if show:\n",
    "            print(scoreDf)\n",
    "        return scoreDf\n",
    "\n",
    "    def gridSearch(self, X, y, validX, validy, nFold=5, verbose=0):\n",
    "        paramsGrids = {\n",
    "            'num_leaves': [5*i for i in range(2,9)],\n",
    "            # 'max_depth': list(range(3,8)),\n",
    "            'min_data_in_leaf': [20*i for i in range(1,10)],\n",
    "            # 'bagging_fraction': [1-0.05*i for i in range(0,5)],\n",
    "            # 'bagging_freq': list(range(0,11,2)),\n",
    "        }\n",
    "        def getEval(params):\n",
    "            iter = self.train(X, y, validX=validX, validy=validy, params=params, verbose=verbose)\n",
    "            return metrics.log_loss(validy, self.predict(validX)), iter\n",
    "        for k,v in paramsGrids.items():\n",
    "            resultDf = pd.DataFrame({k: v})\n",
    "            resultDf['metric_mean'] = list(map(lambda x: getEval({k: x}), v))\n",
    "            print(resultDf)\n",
    "        exit()\n",
    "\n",
    "def main():\n",
    "    # 获取特征工程数据集\n",
    "    if not os.path.isfile(\"../temp/fea1.csv\"): ##？？？？？？？？？？？\n",
    "        df = importDf(\"round1_iflyad_train.txt\")\n",
    "        df['flag'] = 0\n",
    "        predictDf = importDf(\"round1_iflyad_test_feature.txt\")\n",
    "        predictDf['flag'] = -1\n",
    "        originDf = pd.concat([df,predictDf], ignore_index=True)\n",
    "        originDf = feaFactory(originDf)\n",
    "        exportResult(originDf, \"../temp/fea1.csv\")  ##？？？？？？？？？？？\n",
    "    else:\n",
    "        originDf = pd.read_csv(\"../temp/fea1.csv\")   ##？？？？？？？？？？？\n",
    "    originDf.index = list(range(len(originDf)))\n",
    "    tagsMatrix, tagsName = userTagsMatrix(originDf['user_tags'])\n",
    "    print(\"get feature dataset: finished!\")\n",
    "\n",
    "    # 构建训练及测试数据集\n",
    "    tagSelecter = SelectPercentile(chi2, percentile=50)\n",
    "    tagSelecter.fit(tagsMatrix[originDf[originDf.flag>=0].index], originDf[originDf.flag>=0]['click'])\n",
    "    tagsMatrix = tagSelecter.transform(tagsMatrix)\n",
    "    tagsName = tagsName[tagSelecter.get_support()]\n",
    "    cateFea = [\n",
    "        'adid','advert_id','orderid','advert_industry_inner','campaign_id','creative_id','creative_type','creative_tp_dnf','creative_has_deeplink','creative_is_jump',\n",
    "        'app_cate_id','f_channel','app_id','inner_slot_id',\n",
    "        'city','province','carrier','nnt','devtype','os','osv','make','model',\n",
    "\n",
    "        'advert_industry_inner1','creative_area',\n",
    "        'slot_prefix',\n",
    "        'is_wifi',\n",
    "        ]\n",
    "    numFea = [\n",
    "        'creative_width','creative_height',\n",
    "\n",
    "        'day','hour','date','online_days',\n",
    "        'advert_showed','ad_today_num','ad_his_ctr','creative_area_today_num','creative_area_his_ctr','creative_today_num','creative_his_ctr',\n",
    "        'slot_today_num','slot_his_ctr',\n",
    "        'nnt_gtype','osv1','ios_osv1','android_osv1','city_today_num','city_his_ctr',\n",
    "        'tags21_len','tags30_len','tagsLen10_len','tagsAg_len','tagsGd_len','tagsMz_len',\n",
    "    ]\n",
    "    tagFea = ['tag_'+x for x in tagsName]\n",
    "    fea = cateFea + numFea + tagFea\n",
    "    originDf = labelEncoding(originDf, cateFea)\n",
    "\n",
    "    originX = sparse.hstack([sparse.csr_matrix(originDf[cateFea+numFea]), tagsMatrix], 'csr').astype('float32')\n",
    "    dfX = originX[originDf[originDf.flag>=0].index]\n",
    "    dfy = originDf[originDf.flag>=0]['click']\n",
    "    trainX = originX[originDf[(originDf.flag>=0)&(originDf.day<6)].index]\n",
    "    trainy = originDf[(originDf.flag>=0)&(originDf.day<6)]['click']\n",
    "    validX = originX[originDf[(originDf.flag>=0)&(originDf.day==6)].index]\n",
    "    validy = originDf[(originDf.flag>=0)&(originDf.day==6)]['click']\n",
    "    testX = originX[originDf[originDf.flag==-1].index]\n",
    "    # df = originDf[originDf.flag>=0]\n",
    "    # trainDf = df[df.day < 6]\n",
    "    # validDf = df[df.day == 6]\n",
    "    # predictDf = originDf[originDf.flag==-1]\n",
    "\n",
    "    # 训练模型\n",
    "    model = LgbModel(fea, cateFea=cateFea)\n",
    "    # model.gridSearch(trainX, trainy, validX, validy)\n",
    "    iterNum = model.train(trainX, trainy, validX=validX, validy=validy)\n",
    "    model.train(dfX, dfy, num_round=iterNum)\n",
    "    model.feaScore()\n",
    "\n",
    "    # 预测结果\n",
    "    predictDf = pd.DataFrame({'instance_id':originDf[originDf.flag==-1]['instance_id']})\n",
    "    predictDf['predicted_score'] = model.predict(testX)\n",
    "    print(predictDf[['instance_id','predicted_score']].describe())\n",
    "    print(predictDf[['instance_id','predicted_score']].head())\n",
    "    exportResult(predictDf[['instance_id','predicted_score']], \"../result/lgb1.csv\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    startTime = datetime.now()\n",
    "    main()\n",
    "    print('total time:', datetime.now() - startTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
