{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:111: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'DatetimeIndex' and 'datetime.date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6af369dffd2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[0mstartTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'total time:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-6af369dffd2b>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mpredictDf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'flag'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0moriginDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictDf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictDf2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0moriginDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeaFactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginDf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mexportResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginDf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFEA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupyter\\科大讯飞AI营销比赛\\ifly\\code\\feature2.py\u001b[0m in \u001b[0;36mfeaFactory\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0mstartTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatDf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maddTime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maddPublishDay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maddFirstIndustry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupyter\\科大讯飞AI营销比赛\\ifly\\code\\feature2.py\u001b[0m in \u001b[0;36maddTime\u001b[1;34m(df, **params)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mdateMin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'day'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdateMin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hour'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'minute'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_datetime64_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch_to_index_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m             return construct_result(left, result,\n\u001b[0;32m   1048\u001b[0m                                     \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mdispatch_to_index_op\u001b[1;34m(op, left, right, index_class)\u001b[0m\n\u001b[0;32m   1096\u001b[0m         \u001b[0mleft_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft_idx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNullFrequencyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[1;31m# DatetimeIndex and TimedeltaIndex with freq == None raise ValueError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'DatetimeIndex' and 'datetime.date'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*-coding:utf-8-*-\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from scipy import sparse\n",
    "import csv\n",
    "from datetime import *\n",
    "import json, random, os\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, SelectPercentile\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from utils import *\n",
    "from feature2 import feaFactory, userTagsMatrix\n",
    "\n",
    "\n",
    "class LgbModel:\n",
    "    def __init__(self, feaName, cateFea=[], params={}):\n",
    "        self.params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'learning_rate': 0.05,\n",
    "        \t'num_leaves': 150,\n",
    "            'max_depth': -1,\n",
    "            'min_data_in_leaf': 350,\n",
    "            # 'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.9,\n",
    "        \t'bagging_freq': 3,\n",
    "            'verbose': 0,\n",
    "            'seed': 0,\n",
    "        }\n",
    "        self.params.update(**params)\n",
    "        self.feaName = feaName\n",
    "        self.cateFea = cateFea\n",
    "\n",
    "    def train(self, X, y, num_round=8000, validX=None, validy=None, early_stopping=10, verbose=True, params={}):\n",
    "        trainData = lgb.Dataset(X, label=y, feature_name=self.feaName, categorical_feature=self.cateFea)\n",
    "        trainParam = self.params\n",
    "        trainParam.update(params)\n",
    "        if isinstance(validX, (pd.DataFrame, sparse.csr_matrix)):\n",
    "            validData = trainData.create_valid(validX, label=validy)\n",
    "            bst = lgb.train(trainParam, trainData, num_boost_round=num_round, valid_sets=[trainData,validData], valid_names=['train', 'valid'], early_stopping_rounds=early_stopping, verbose_eval=verbose)\n",
    "        else:\n",
    "            bst = lgb.train(trainParam, trainData, valid_sets=trainData, num_boost_round=num_round, verbose_eval=verbose)\n",
    "        self.bst = bst\n",
    "        return bst.best_iteration\n",
    "\n",
    "    def cv(self, X, y, nfold=5, num_round=8000, early_stopping=10, verbose=True, params={}):\n",
    "        trainParam = self.params\n",
    "        trainParam.update(params)\n",
    "        trainData = lgb.Dataset(X, label=y, feature_name=self.feaName, categorical_feature=self.cateFea)\n",
    "        result = lgb.cv(trainParam, trainData, feature_name=self.feaName, categorical_feature=self.cateFea, num_boost_round=num_round, nfold=nfold, early_stopping_rounds=early_stopping, verbose_eval=verbose)\n",
    "        return result\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.bst.predict(X)\n",
    "\n",
    "    def feaScore(self, show=True):\n",
    "        scoreDf = pd.DataFrame({'fea': self.feaName, 'importance': self.bst.feature_importance()})\n",
    "        scoreDf.sort_values(['importance'], ascending=False, inplace=True)\n",
    "        if show:\n",
    "            print(scoreDf[scoreDf.importance>0])\n",
    "        return scoreDf\n",
    "\n",
    "    def gridSearch(self, X, y, validX, validy, nFold=5, verbose=0):\n",
    "        paramsGrids = {\n",
    "            'num_leaves': [20*i for i in range(2,10)],\n",
    "            # 'max_depth': list(range(8,13)),\n",
    "            # 'min_data_in_leaf': [50*i for i in range(2,10)],\n",
    "            # 'bagging_fraction': [1-0.05*i for i in range(0,5)],\n",
    "            # 'bagging_freq': list(range(0,10)),\n",
    "\n",
    "        }\n",
    "        def getEval(params):\n",
    "            iter = self.train(X, y, validX=validX, validy=validy, params=params, verbose=verbose)\n",
    "            return metrics.log_loss(validy, self.predict(validX)), iter\n",
    "        for k,v in paramsGrids.items():\n",
    "            resultDf = pd.DataFrame({k: v})\n",
    "            resultDf['metric_mean'] = list(map(lambda x: getEval({k: x}), v))\n",
    "            print(resultDf)\n",
    "        exit()\n",
    "\n",
    "def main():\n",
    "    ORIGIN_DATA_PATH = \"../data/\"\n",
    "    FEA_PATH = \"../temp/fea2.csv\"\n",
    "    TAGS_PATH = \"../temp/user_tags2.npz\"\n",
    "    TAGS_NAME_PATH = \"../temp/user_tags_name2.txt\"\n",
    "    SPARSE_COL_PATH = \"../temp/lgb2_sparse_col.npz\"\n",
    "    SPARSE_COLNAME_PATH = \"../temp/lgb2_sparse_colname.txt\"\n",
    "\n",
    "    # 获取特征工程数据集\n",
    "    if not os.path.isfile(FEA_PATH):\n",
    "        df1 = importDf(ORIGIN_DATA_PATH + \"round1_iflyad_train.txt\")\n",
    "        df1['flag'] = 1\n",
    "        df2 = importDf(ORIGIN_DATA_PATH + \"round2_iflyad_train.txt\")\n",
    "        df2['flag'] = 2\n",
    "        df1.drop(df1[df1.instance_id.isin(df2.instance_id)].index, inplace=True)\n",
    "        predictDf = importDf(ORIGIN_DATA_PATH + \"round2_iflyad_test_feature.txt\")\n",
    "        predictDf['flag'] = -1\n",
    "        predictDf2 = importDf(ORIGIN_DATA_PATH + \"round1_iflyad_test_feature.txt\")\n",
    "        predictDf2.drop(predictDf2[predictDf2.instance_id.isin(predictDf.instance_id)].index, inplace=True)\n",
    "        predictDf2['flag'] = -2\n",
    "        originDf = pd.concat([df1, df2, predictDf, predictDf2], ignore_index=True)\n",
    "        originDf = feaFactory(originDf)\n",
    "        exportResult(originDf, FEA_PATH)\n",
    "    else:\n",
    "        originDf = pd.read_csv(FEA_PATH)\n",
    "    print(\"feature dataset prepare: finished!\")\n",
    "\n",
    "\n",
    "    # 筛选稀疏特征\n",
    "    if not os.path.isfile(SPARSE_COL_PATH):\n",
    "        if not os.path.isfile(TAGS_PATH):\n",
    "            sparseCsr, sparseFea = userTagsMatrix(originDf['user_tags'])\n",
    "            sparse.save_npz(TAGS_PATH, sparseCsr)\n",
    "            fp = open(TAGS_NAME_PATH, \"w\")\n",
    "            fp.write(\",\".join(sparseFea))\n",
    "            fp.close()\n",
    "        else:\n",
    "            sparseCsr = sparse.load_npz(TAGS_PATH)\n",
    "            fp = open(TAGS_NAME_PATH)\n",
    "            sparseFea = None\n",
    "            try:\n",
    "                sparseFea = fp.read().split(\",\")\n",
    "            finally:\n",
    "                fp.close()\n",
    "        sparseFea = [\"tag_%s\"%x for x in sparseFea]\n",
    "        selecter = SelectPercentile(chi2, percentile=20)\n",
    "        selecter.fit(sparseCsr[originDf[originDf.flag>=0].index.tolist()], originDf[originDf.flag>=0]['click'])\n",
    "        sparseCsr = selecter.transform(sparseCsr)\n",
    "        sparseFea = np.array(sparseFea)[selecter.get_support()].tolist()\n",
    "        print(\"%d tags fea select: finished!\" % len(sparseFea))\n",
    "\n",
    "        onehotList = ['creative_type','creative_dpi','advert_industry_inner1','slot_prefix','region','carrier','nnt','devtype','os']\n",
    "        onehotDf = pd.get_dummies(originDf[onehotList], columns=onehotList, sparse=True)\n",
    "        sparseCsr = sparse.hstack([sparseCsr, sparse.csr_matrix(onehotDf)], 'csr')\n",
    "        # print(onehotDf.columns[:5])\n",
    "        sparseFea.extend(onehotDf.columns)\n",
    "        print(\"onehot fea:\", len(onehotDf.columns))\n",
    "\n",
    "        selectList = ['adid','inner_slot_id','make','creative_id','app_id']\n",
    "        for x in selectList:\n",
    "            onehotDf = pd.get_dummies(originDf[[x]], columns=[x], sparse=True)\n",
    "            onehotCsr = sparse.csr_matrix(onehotDf)\n",
    "            selecter = SelectPercentile(percentile=5)\n",
    "            selecter.fit(onehotCsr[originDf[originDf.flag>=0].index.tolist()], originDf[originDf.flag>=0]['click'])\n",
    "            sparseCsr = sparse.hstack([sparseCsr, selecter.transform(onehotCsr)], 'csr')\n",
    "            sparseFea.extend(onehotDf.columns[selecter.get_support()])\n",
    "            print('select %s onehot: %d' % (x, len(selecter.get_support(indices=True))))\n",
    "\n",
    "        sparse.save_npz(SPARSE_COL_PATH, sparseCsr)\n",
    "        fp = open(SPARSE_COLNAME_PATH, \"w\")\n",
    "        fp.write(\"||\".join(sparseFea).replace(\" \",\"_\"))\n",
    "        fp.close()\n",
    "    else:\n",
    "        sparseCsr = sparse.load_npz(SPARSE_COL_PATH)\n",
    "        fp = open(SPARSE_COLNAME_PATH)\n",
    "        sparseFea = np.array(list(range(sparseCsr.shape[1]))).astype(str).tolist()\n",
    "        try:\n",
    "            sparseFea = fp.read().replace(\" \",\"_\").split(\"||\")\n",
    "        finally:\n",
    "            fp.close()\n",
    "    print(\"sparse dataset prepare: finished!\")\n",
    "\n",
    "    # 全部特征拼接\n",
    "    cateFea = [\n",
    "        'adid','advert_id','orderid','advert_industry_inner','campaign_id','creative_id','creative_type','creative_tp_dnf',\n",
    "        'app_cate_id','f_channel','app_id','inner_slot_id',\n",
    "        'city','province','carrier','nnt','devtype','os','osv','make','model',\n",
    "\n",
    "        'advert_industry_inner1','creative_dpi',\n",
    "        'slot_prefix',#'slot2',\n",
    "        'region',\n",
    "        ]\n",
    "    numFea = [\n",
    "        'creative_width','creative_height','creative_has_deeplink','creative_is_jump',\n",
    "\n",
    "        'hour','hour_minute','minute',#'online_days','day',\n",
    "        'creative_area',#'creative_his_ctr',#'ad_his_ctr','creative_area_his_ctr',# 'advert_showed',#'ad_today_num','creative_area_today_num','creative_today_num',\n",
    "        'app_tail_number',#'slot_his_ctr',# 'slot_today_num',\n",
    "        'cityCode','osv1','ios_osv1','android_osv1','isDirectCity','nnt_gtype',#'city_his_ctr',#'city_today_num','is_wifi',\n",
    "        'tags_num','tags21_len','tags30_len','tagsLen10_len','tagsAg_len','tagsGd_len','tagsMz_len',#'tags21_mean','tags30_mean',\n",
    "        # 'ad_today_num_ratio','dpi_today_num_ratio','creative_today_num_ratio','slot_today_num_ratio','app_today_num_ratio','city_today_num_ratio',\n",
    "        'ad_num_ratio','dpi_num_ratio','creative_num_ratio','slot_num_ratio','app_num_ratio','city_num_ratio','make_num_ratio','model_num_ratio',#'advert_num_ratio','industry_num_ratio','campaign_num_ratio',\n",
    "        'creative_ad_nunique','app_slot_nunique','model_dpi_nunique','order_ad_nunique','slot_ad_nunique','slot_creative_nunique','ad_app_nunique','ad_slot_nunique',#'campaign_order_nunique','campaign_creative_nunique',\n",
    "        ]\n",
    "    originDf = labelEncoding(originDf, cateFea)\n",
    "    fea = cateFea + numFea\n",
    "    originX = sparse.hstack([sparse.csr_matrix(originDf[fea].astype(float)), sparseCsr], 'csr').astype('float32')\n",
    "    fea.extend(sparseFea)\n",
    "    print('model dataset size:', originX.shape)\n",
    "    print(\"model dataset prepare: finished!\")\n",
    "\n",
    "    # 划分数据集\n",
    "    dfX = originX[originDf[originDf.flag>=0].index.tolist()]\n",
    "    dfy = originDf[originDf.flag>=0]['click']\n",
    "    trainX = originX[originDf[(originDf.flag>=0)&(originDf.day<6)].index.tolist()]\n",
    "    trainy = originDf[(originDf.flag>=0)&(originDf.day<6)]['click']\n",
    "    validX = originX[originDf[(originDf.flag>=0)&(originDf.day==6)].sample(frac=0.7, random_state=0).index.tolist()]\n",
    "    validy = originDf[(originDf.flag>=0)&(originDf.day==6)].sample(frac=0.7, random_state=0)['click']\n",
    "    testX = originX[originDf[originDf.flag==-1].index.tolist()]\n",
    "    print('training dataset prepare: finished!')\n",
    "\n",
    "    # 训练模型\n",
    "    model = LgbModel(fea)\n",
    "    model.gridSearch(trainX, trainy, validX, validy)\n",
    "    model.cv(dfX, dfy, nfold=5)\n",
    "    iterNum = model.train(trainX, trainy, validX=validX, validy=validy, params={'learning_rate':0.02})\n",
    "    model.train(dfX, dfy, num_round=iterNum, params={'learning_rate':0.02}, verbose=False)\n",
    "    model.feaScore()\n",
    "\n",
    "    # 预测结果\n",
    "    predictDf = originDf[originDf.flag==-1][['instance_id','hour']]\n",
    "    predictDf['predicted_score'] = model.predict(testX)\n",
    "    print(predictDf[['instance_id','predicted_score']].describe())\n",
    "    print(predictDf[['instance_id','predicted_score']].head())\n",
    "    print(predictDf.groupby('hour')['predicted_score'].mean())\n",
    "    exportResult(predictDf[['instance_id','predicted_score']], \"../result/lgb2.csv\")\n",
    "\n",
    "    # 5折stacking\n",
    "    print('training oof...')\n",
    "    df2 = originDf[originDf.flag>=0][['instance_id','hour','click']]\n",
    "    df2['predicted_score'], predictDf['predicted_score'] = getOof(model, dfX, dfy, testX)\n",
    "    print('cv5 valid loss:', metrics.log_loss(df2['click'], df2['predicted_score']))\n",
    "    print(predictDf[['instance_id','predicted_score']].describe())\n",
    "    print(predictDf[['instance_id','predicted_score']].head())\n",
    "    print(predictDf.groupby('hour')['predicted_score'].mean())\n",
    "    exportResult(df2[['instance_id','predicted_score']], \"../result/lgb2_oof_train.csv\")\n",
    "    exportResult(predictDf[['instance_id','predicted_score']], \"../result/lgb2_oof_test.csv\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    startTime = datetime.now()\n",
    "    main()\n",
    "    print('total time:', datetime.now() - startTime)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
